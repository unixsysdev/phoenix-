{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen3 Coder — Diffusion Infill + Bend/HVM (Colab)\n",
        "\n",
        "Self‑contained notebook that:\n",
        "- Installs dependencies in Python (no repo shell scripts).\n",
        "- Downloads and loads the full Qwen3‑Coder‑30B‑A3B‑Instruct‑FP8 model (80GB VRAM assumed).\n",
        "- Implements masked diffusion infill entirely in‑notebook (no AR or length head).\n",
        "- Optionally installs Bend/HVM and verifies Bend code.\n",
        "- Optionally clones the repo for reference/configs without executing its scripts.\n",
        "\n",
        "Enable GPU in Colab: Runtime → Change runtime type → GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env_check"
      },
      "outputs": [],
      "source": [
        "import torch, platform, sys, os\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('Torch:', getattr(torch, '__version__', 'not installed'))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "print('GPU name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "Use pip magics (no subprocess). If you prefer the repo's full requirements, a cell below installs them too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pip_install"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install transformers>=4.51.0 accelerate>=0.34.0 peft>=0.12.0 bitsandbytes>=0.44.0 safetensors>=0.4.0 einops>=0.7.0 pyyaml>=6.0 tqdm>=4.66.0 rich>=13.6.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clone Repo (SSH with HTTPS fallback)\n",
        "We clone the repo for code and configs, but we won’t run its shell scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "git_clone"
      },
      "outputs": [],
      "source": [
        "REPO_DIR='/content/phoenix-'\n",
        "!rm -rf $REPO_DIR\n",
        "!git clone --depth 1 git@github.com:unixsysdev/phoenix-.git $REPO_DIR || git clone --depth 1 https://github.com/unixsysdev/phoenix-.git $REPO_DIR\n",
        "%cd $REPO_DIR\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Install Full Requirements\n",
        "The repo's requirements include heavy extras (flash-attn/xformers/deepspeed) that may fail on Colab. Use only if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "full_requirements_optional"
      },
      "outputs": [],
      "source": [
        "# Optional and may be slow\n",
        "# !pip -q install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Clone Repo (no scripts executed)\n",
        "Set `REPO_URL` if you want the sources/configs locally. This notebook does not call any repo shell scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "repo_clone"
      },
      "outputs": [],
      "source": [
        "import os, sys, subprocess\n",
        "REPO_URL = ''  # optional: set to your repo URL if needed\n",
        "REPO_DIR = '/content/qwen3_diffusion_repo'\n",
        "if REPO_URL:\n",
        "    if not os.path.exists(REPO_DIR):\n",
        "        subprocess.run(['git', 'clone', REPO_URL, REPO_DIR], check=True)\n",
        "    sys.path.append(os.path.join(REPO_DIR, 'src'))\n",
        "print('Repo dir (optional):', REPO_DIR, '(exists:', os.path.exists(REPO_DIR), ')')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Diffusion‑Only Training (smaller model)\n",
        "We’ll target a 7B coder model to fit <80GB VRAM and focus on diffusion loss (no AR/length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "write_config"
      },
      "outputs": [],
      "source": [
        "import yaml, os, textwrap\n",
        "cfg_path = 'configs/qwen_diffusion_colab.yaml'\n",
        "cfg = {\n",
        "  'model': {\n",
        "    'name': 'Qwen/Qwen2.5-Coder-7B-Instruct',\n",
        "    'type': 'qwen',\n",
        "    'device_map': 'auto'\n",
        "  },\n",
        "  'training': {\n",
        "    'micro_batch_size': 1,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'max_steps': 1000,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 0.01,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'use_lora': True,\n",
        "    'lora_config_path': 'configs/lora_configs.yaml',\n",
        "    'multi_head': True,\n",
        "    'heads': ['diffusion'],\n",
        "    'diffusion': {\n",
        "      'mask_ratio_range': [0.2, 0.8],\n",
        "      'steps': 20,\n",
        "      'inference_steps': 20,\n",
        "      'scheduler': 'cosine'\n",
        "    },\n",
        "    'seed_diffusion': { 'on_policy_learning': False },\n",
        "    'save_steps': 200,\n",
        "    'save_total_limit': 2,\n",
        "    'logging_steps': 10,\n",
        "    'eval_steps': 0,\n",
        "    'output_dir': 'logs/colab_diffusion'\n",
        "  },\n",
        "  'data': {\n",
        "    'train_path': 'data/train_samples.json',\n",
        "    'eval_path': 'data/val_samples.json',\n",
        "    'max_length': 512,\n",
        "    'truncation': True,\n",
        "    'padding': 'max_length',\n",
        "    'shuffle': True,\n",
        "    'seed': 42,\n",
        "    'task_weights': { 'ar': 0.0, 'diffusion': 1.0, 'length': 0.0 }\n",
        "  },\n",
        "  'verifier': { 'bend': {'enabled': False}, 'hvm': {'enabled': False}, 'verification_frequency': 0 },\n",
        "  'logging': { 'level': 'INFO', 'log_dir': 'logs' },\n",
        "  'hardware': { 'gpu_ids': [0] }\n",
        "}\n",
        "with open(cfg_path, 'w') as f: yaml.safe_dump(cfg, f)\n",
        "print('Wrote', cfg_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train (Diffusion‑only LoRA)\n",
        "Runs training using the repo’s Python entrypoint (no shell scripts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_run"
      },
      "outputs": [],
      "source": [
        "!python -m src.training.train \\\n",
        "  --config_file configs/qwen_diffusion_colab.yaml \\\n",
        "  --data_dir data \\\n",
        "  --output_dir logs/colab_diffusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate (Diffusion Infill)\n",
        "Use the trained adapters at `logs/colab_diffusion/final/model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "infill_gen"
      },
      "outputs": [],
      "source": [
        "!python -m src.inference.generator \\\n",
        "  --model_path \"Qwen/Qwen2.5-Coder-7B-Instruct\" \\\n",
        "  --adapter_path \"logs/colab_diffusion/final/model\" \\\n",
        "  --config_path configs/lora_configs.yaml \\\n",
        "  --mode infill \\\n",
        "  --prompt \"def quicksort(arr):\\n    \"\"\"Sort a list using quicksort.\"\"\"\\n    <|mask|>\" \\\n",
        "  --steps 20 \\\n",
        "  --temperature 0.7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Install Bend/HVM and Enable On‑Policy Verification\n",
        "Installs rust/cargo and bend/hvm, then toggles verification in the config and resumes training briefly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bend_enable"
      },
      "outputs": [],
      "source": [
        "# Install rustup + cargo + bend/hvm\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "import os\n",
        "os.environ['PATH'] = os.path.expanduser('~/.cargo/bin') + os.pathsep + os.environ['PATH']\n",
        "!source ~/.cargo/env && cargo install bend-lang\n",
        "!source ~/.cargo/env && cargo install hvm\n",
        "!bend --version\n",
        "!hvm --version\n",
        "# Enable verification in config\n",
        "import yaml\n",
        "cfg_path = 'configs/qwen_diffusion_colab.yaml'\n",
        "cfg = yaml.safe_load(open(cfg_path))\n",
        "cfg['verifier'] = {\n",
        "  'bend': {'enabled': True, 'path': 'bend', 'timeout': 30, 'use_cuda': True},\n",
        "  'hvm': {'enabled': True, 'path': 'hvm', 'timeout': 30},\n",
        "  'verification_frequency': 200\n",
        "}\n",
        "cfg['training']['seed_diffusion'] = {'on_policy_learning': True}\n",
        "open(cfg_path,'w').write(yaml.safe_dump(cfg))\n",
        "print('Verification enabled in', cfg_path)\n",
        "# Resume a short run with verification (adjust steps as desired)\n",
        "!python -m src.training.train \\\n",
        "  --config_file configs/qwen_diffusion_colab.yaml \\\n",
        "  --data_dir data \\\n",
        "  --output_dir logs/colab_diffusion \\\n",
        "  --resume_from logs/colab_diffusion/final\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
